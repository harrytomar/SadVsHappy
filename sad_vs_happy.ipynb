{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /home/harish/anaconda3/lib/python3.6/site-packages (2.0.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /home/harish/anaconda3/lib/python3.6/site-packages (from tensorflow) (0.1.7)\n",
      "Processing /home/harish/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd/gast-0.2.2-cp36-none-any.whl\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /home/harish/anaconda3/lib/python3.6/site-packages (from tensorflow) (3.10.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in /home/harish/anaconda3/lib/python3.6/site-packages (from tensorflow) (1.0.8)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/harish/anaconda3/lib/python3.6/site-packages (from tensorflow) (1.12.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /home/harish/anaconda3/lib/python3.6/site-packages (from tensorflow) (0.8.1)\n",
      "Requirement already satisfied: tensorboard<2.1.0,>=2.0.0 in /home/harish/anaconda3/lib/python3.6/site-packages (from tensorflow) (2.0.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.1.0,>=2.0.0 in /home/harish/anaconda3/lib/python3.6/site-packages (from tensorflow) (2.0.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/harish/anaconda3/lib/python3.6/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /home/harish/anaconda3/lib/python3.6/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/harish/anaconda3/lib/python3.6/site-packages (from tensorflow) (0.33.6)\n",
      "Requirement already satisfied: astor>=0.6.0 in /home/harish/anaconda3/lib/python3.6/site-packages (from tensorflow) (0.8.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /home/harish/anaconda3/lib/python3.6/site-packages (from tensorflow) (1.11.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/harish/anaconda3/lib/python3.6/site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /home/harish/anaconda3/lib/python3.6/site-packages (from tensorflow) (1.17.3)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /home/harish/anaconda3/lib/python3.6/site-packages (from tensorflow) (1.24.3)\n",
      "Requirement already satisfied: setuptools in /home/harish/anaconda3/lib/python3.6/site-packages (from protobuf>=3.6.1->tensorflow) (41.6.0.post20191030)\n",
      "Requirement already satisfied: h5py in /home/harish/anaconda3/lib/python3.6/site-packages (from keras-applications>=1.0.8->tensorflow) (2.7.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /home/harish/anaconda3/lib/python3.6/site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/harish/anaconda3/lib/python3.6/site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (0.15.5)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/harish/anaconda3/lib/python3.6/site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/harish/anaconda3/lib/python3.6/site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (3.1.1)\n",
      "Requirement already satisfied: cachetools>=2.0.0 in /home/harish/anaconda3/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (3.1.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/harish/anaconda3/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (0.2.7)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /home/harish/anaconda3/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (4.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/harish/anaconda3/lib/python3.6/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (1.2.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/harish/anaconda3/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (0.4.7)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/harish/anaconda3/lib/python3.6/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in /home/harish/anaconda3/lib/python3.6/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/harish/anaconda3/lib/python3.6/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/harish/anaconda3/lib/python3.6/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/harish/anaconda3/lib/python3.6/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (1.24.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/harish/anaconda3/lib/python3.6/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (2019.9.11)\n",
      "Installing collected packages: gast\n",
      "  Found existing installation: gast 0.3.2\n",
      "    Uninstalling gast-0.3.2:\n",
      "      Successfully uninstalled gast-0.3.2\n",
      "Successfully installed gast-0.2.2\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /home/harish/anaconda3/lib/python3.6/site-packages (4.36.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tflearn in /home/harish/anaconda3/lib/python3.6/site-packages (0.3.2)\r\n",
      "Requirement already satisfied: numpy in /home/harish/anaconda3/lib/python3.6/site-packages (from tflearn) (1.17.3)\r\n",
      "Requirement already satisfied: six in /home/harish/anaconda3/lib/python3.6/site-packages (from tflearn) (1.12.0)\r\n",
      "Requirement already satisfied: Pillow in /home/harish/anaconda3/lib/python3.6/site-packages (from tflearn) (6.2.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install tflearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: pip in /home/harish/anaconda3/lib/python3.6/site-packages (19.3.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /home/harish/anaconda3/lib/python3.6/site-packages (4.1.1.26)\r\n",
      "Requirement already satisfied: numpy>=1.11.3 in /home/harish/anaconda3/lib/python3.6/site-packages (from opencv-python) (1.17.3)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2                 # working with, mainly resizing, images\n",
    "import numpy as np         # dealing with arrays\n",
    "import os                  # dealing with directories\n",
    "from random import shuffle # mixing up or currently ordered data that might lead our network astray in training.\n",
    "from tqdm import tqdm      # a nice pretty percentage bar for tasks. Thanks to viewer Daniel BA1/4hler for this suggestion\n",
    "\n",
    "TRAIN_DIR = 'train1'\n",
    "TEST_DIR = 'test1'\n",
    "IMG_SIZE = 50\n",
    "LR = 1e-3\n",
    "MODEL_NAME = 'sadvshappy-{}-{}.model'.format(LR, '2conv-basic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /home/harish/.cache/pip/wheels/d7/de/2e/efa132238792efb6459a96e85916ef8597fcb3d2ae51590dfd/wrapt-1.11.2-cp36-cp36m-linux_x86_64.whl\n",
      "Installing collected packages: wrapt\n",
      "Successfully installed wrapt-1.11.2\n"
     ]
    }
   ],
   "source": [
    "!pip install wrapt --upgrade --ignore-installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /home/harish/anaconda3/lib/python3.6/site-packages (2.0.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /home/harish/anaconda3/lib/python3.6/site-packages (from tensorflow) (0.1.7)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/harish/anaconda3/lib/python3.6/site-packages (from tensorflow) (1.12.0)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /home/harish/anaconda3/lib/python3.6/site-packages (from tensorflow) (3.10.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /home/harish/anaconda3/lib/python3.6/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/harish/anaconda3/lib/python3.6/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /home/harish/anaconda3/lib/python3.6/site-packages (from tensorflow) (1.24.3)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/harish/anaconda3/lib/python3.6/site-packages (from tensorflow) (0.33.6)\n",
      "Requirement already satisfied: gast==0.2.2 in /home/harish/anaconda3/lib/python3.6/site-packages (from tensorflow) (0.2.2)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /home/harish/anaconda3/lib/python3.6/site-packages (from tensorflow) (0.8.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in /home/harish/anaconda3/lib/python3.6/site-packages (from tensorflow) (1.0.8)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/harish/anaconda3/lib/python3.6/site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /home/harish/anaconda3/lib/python3.6/site-packages (from tensorflow) (1.17.3)\n",
      "Requirement already satisfied: tensorboard<2.1.0,>=2.0.0 in /home/harish/anaconda3/lib/python3.6/site-packages (from tensorflow) (2.0.1)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /home/harish/anaconda3/lib/python3.6/site-packages (from tensorflow) (1.11.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.1.0,>=2.0.0 in /home/harish/anaconda3/lib/python3.6/site-packages (from tensorflow) (2.0.1)\n",
      "Requirement already satisfied: astor>=0.6.0 in /home/harish/anaconda3/lib/python3.6/site-packages (from tensorflow) (0.8.0)\n",
      "Requirement already satisfied: setuptools in /home/harish/anaconda3/lib/python3.6/site-packages (from protobuf>=3.6.1->tensorflow) (41.6.0.post20191030)\n",
      "Requirement already satisfied: h5py in /home/harish/anaconda3/lib/python3.6/site-packages (from keras-applications>=1.0.8->tensorflow) (2.7.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/harish/anaconda3/lib/python3.6/site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (3.1.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /home/harish/anaconda3/lib/python3.6/site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/harish/anaconda3/lib/python3.6/site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (0.15.5)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/harish/anaconda3/lib/python3.6/site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /home/harish/anaconda3/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (4.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/harish/anaconda3/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (0.2.7)\n",
      "Requirement already satisfied: cachetools>=2.0.0 in /home/harish/anaconda3/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (3.1.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/harish/anaconda3/lib/python3.6/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (1.2.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /home/harish/anaconda3/lib/python3.6/site-packages (from rsa>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (0.4.7)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/harish/anaconda3/lib/python3.6/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in /home/harish/anaconda3/lib/python3.6/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/harish/anaconda3/lib/python3.6/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/harish/anaconda3/lib/python3.6/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/harish/anaconda3/lib/python3.6/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (2019.9.11)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/harish/anaconda3/lib/python3.6/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (1.24.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_img(img):\n",
    "    word_label = img.split('.')[-3]\n",
    "    # conversion to one-hot array [cat,dog]\n",
    "    #                            [much cat, no dog]\n",
    "    if word_label == 'happy': return [1,0]\n",
    "    #                             [no cat, very doggo]\n",
    "    elif word_label == 'sad': return [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_data():\n",
    "    training_data = []\n",
    "    for img in tqdm(os.listdir(TRAIN_DIR)):\n",
    "        label = label_img(img)\n",
    "        path = os.path.join(TRAIN_DIR,img)\n",
    "        img = cv2.imread(path,cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n",
    "        training_data.append([np.array(img),np.array(label)])\n",
    "    shuffle(training_data)\n",
    "    np.save('train_data2.py', training_data)\n",
    "    return training_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_test_data():\n",
    "    testing_data = []\n",
    "  \n",
    "    for img in tqdm(os.listdir(TEST_DIR)):\n",
    "        path = os.path.join(TEST_DIR,img)\n",
    "        img_num = img.split('.')[0]\n",
    "        img = cv2.imread(path,cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n",
    "        testing_data.append([np.array(img), img_num])\n",
    "        \n",
    "    shuffle(testing_data)\n",
    "    np.save('test_data2.py', testing_data)\n",
    "    return testing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [00:00<00:00, 234.76it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data = create_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/harish/anaconda3/lib/python3.6/site-packages/tflearn/helpers/summarizer.py:9: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/harish/anaconda3/lib/python3.6/site-packages/tflearn/helpers/trainer.py:25: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/harish/anaconda3/lib/python3.6/site-packages/tflearn/collections.py:13: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/harish/anaconda3/lib/python3.6/site-packages/tflearn/config.py:123: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/harish/anaconda3/lib/python3.6/site-packages/tflearn/config.py:129: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/harish/anaconda3/lib/python3.6/site-packages/tflearn/config.py:131: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/harish/anaconda3/lib/python3.6/site-packages/tflearn/layers/core.py:81: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/harish/anaconda3/lib/python3.6/site-packages/tflearn/initializations.py:119: calling UniformUnitScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/harish/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py:507: UniformUnitScaling.__init__ (from tensorflow.python.ops.init_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.initializers.variance_scaling instead with distribution=uniform to get equivalent behavior.\n",
      "WARNING:tensorflow:From /home/harish/anaconda3/lib/python3.6/site-packages/tflearn/layers/conv.py:552: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/harish/anaconda3/lib/python3.6/site-packages/tflearn/initializations.py:174: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/harish/anaconda3/lib/python3.6/site-packages/tflearn/layers/core.py:239: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/harish/anaconda3/lib/python3.6/site-packages/tflearn/optimizers.py:238: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/harish/anaconda3/lib/python3.6/site-packages/tflearn/objectives.py:66: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/harish/anaconda3/lib/python3.6/site-packages/tflearn/summaries.py:46: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/harish/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/harish/anaconda3/lib/python3.6/site-packages/tflearn/helpers/trainer.py:134: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "---------------------------------\n",
      "Run id: sadvshappy-0.001-2conv-basic.model\n",
      "Log directory: log/\n",
      "INFO:tensorflow:Summary name Accuracy/ (raw) is illegal; using Accuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 45\n",
      "Validation samples: 35\n",
      "--\n",
      "Training Step: 1  | time: 2.910s\n",
      "| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 | val_loss: 0.69241 - val_acc: 0.6286 -- iter: 45/45\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32m0.62384\u001b[0m\u001b[0m | time: 1.094s\n",
      "| Adam | epoch: 002 | loss: 0.62384 - acc: 0.4200 | val_loss: 0.69064 - val_acc: 0.6286 -- iter: 45/45\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32m0.68046\u001b[0m\u001b[0m | time: 1.100s\n",
      "| Adam | epoch: 003 | loss: 0.68046 - acc: 0.4945 | val_loss: 0.68812 - val_acc: 0.6286 -- iter: 45/45\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32m0.68987\u001b[0m\u001b[0m | time: 1.101s\n",
      "| Adam | epoch: 004 | loss: 0.68987 - acc: 0.5070 | val_loss: 0.68236 - val_acc: 0.6286 -- iter: 45/45\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32m0.69155\u001b[0m\u001b[0m | time: 1.113s\n",
      "| Adam | epoch: 005 | loss: 0.69155 - acc: 0.5098 | val_loss: 0.67256 - val_acc: 0.6286 -- iter: 45/45\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32m0.69148\u001b[0m\u001b[0m | time: 1.115s\n",
      "| Adam | epoch: 006 | loss: 0.69148 - acc: 0.5107 | val_loss: 0.66907 - val_acc: 0.6286 -- iter: 45/45\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32m0.69154\u001b[0m\u001b[0m | time: 1.178s\n",
      "| Adam | epoch: 007 | loss: 0.69154 - acc: 0.5109 | val_loss: 0.67312 - val_acc: 0.6286 -- iter: 45/45\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32m0.69152\u001b[0m\u001b[0m | time: 1.194s\n",
      "| Adam | epoch: 008 | loss: 0.69152 - acc: 0.5110 | val_loss: 0.67569 - val_acc: 0.6286 -- iter: 45/45\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32m0.69079\u001b[0m\u001b[0m | time: 1.167s\n",
      "| Adam | epoch: 009 | loss: 0.69079 - acc: 0.5111 | val_loss: 0.67231 - val_acc: 0.6286 -- iter: 45/45\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32m0.68923\u001b[0m\u001b[0m | time: 1.179s\n",
      "| Adam | epoch: 010 | loss: 0.68923 - acc: 0.5111 | val_loss: 0.66632 - val_acc: 0.6286 -- iter: 45/45\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32m0.68807\u001b[0m\u001b[0m | time: 1.133s\n",
      "| Adam | epoch: 011 | loss: 0.68807 - acc: 0.5111 | val_loss: 0.66124 - val_acc: 0.6286 -- iter: 45/45\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32m0.68575\u001b[0m\u001b[0m | time: 1.096s\n",
      "| Adam | epoch: 012 | loss: 0.68575 - acc: 0.5111 | val_loss: 0.65997 - val_acc: 0.6286 -- iter: 45/45\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32m0.68179\u001b[0m\u001b[0m | time: 1.096s\n",
      "| Adam | epoch: 013 | loss: 0.68179 - acc: 0.5111 | val_loss: 0.63977 - val_acc: 0.6286 -- iter: 45/45\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32m0.67535\u001b[0m\u001b[0m | time: 1.103s\n",
      "| Adam | epoch: 014 | loss: 0.67535 - acc: 0.5111 | val_loss: 0.63935 - val_acc: 0.6857 -- iter: 45/45\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32m0.66518\u001b[0m\u001b[0m | time: 1.128s\n",
      "| Adam | epoch: 015 | loss: 0.66518 - acc: 0.5111 | val_loss: 0.61797 - val_acc: 0.7143 -- iter: 45/45\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32m0.65018\u001b[0m\u001b[0m | time: 1.081s\n",
      "| Adam | epoch: 016 | loss: 0.65018 - acc: 0.5528 | val_loss: 0.66974 - val_acc: 0.6857 -- iter: 45/45\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32m0.62941\u001b[0m\u001b[0m | time: 1.118s\n",
      "| Adam | epoch: 017 | loss: 0.62941 - acc: 0.5938 | val_loss: 0.65600 - val_acc: 0.6857 -- iter: 45/45\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32m0.61417\u001b[0m\u001b[0m | time: 1.124s\n",
      "| Adam | epoch: 018 | loss: 0.61417 - acc: 0.7113 | val_loss: 0.63634 - val_acc: 0.7143 -- iter: 45/45\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32m0.62026\u001b[0m\u001b[0m | time: 1.109s\n",
      "| Adam | epoch: 019 | loss: 0.62026 - acc: 0.6742 | val_loss: 0.68740 - val_acc: 0.4857 -- iter: 45/45\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32m0.58046\u001b[0m\u001b[0m | time: 1.115s\n",
      "| Adam | epoch: 020 | loss: 0.58046 - acc: 0.7146 | val_loss: 0.65872 - val_acc: 0.6571 -- iter: 45/45\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32m0.58285\u001b[0m\u001b[0m | time: 1.117s\n",
      "| Adam | epoch: 021 | loss: 0.58285 - acc: 0.7963 | val_loss: 0.74220 - val_acc: 0.7143 -- iter: 45/45\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32m0.54745\u001b[0m\u001b[0m | time: 1.084s\n",
      "| Adam | epoch: 022 | loss: 0.54745 - acc: 0.8374 | val_loss: 0.71958 - val_acc: 0.7143 -- iter: 45/45\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 23  | total loss: \u001b[1m\u001b[32m0.56103\u001b[0m\u001b[0m | time: 1.090s\n",
      "| Adam | epoch: 023 | loss: 0.56103 - acc: 0.7943 | val_loss: 0.68902 - val_acc: 0.5429 -- iter: 45/45\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32m0.54477\u001b[0m\u001b[0m | time: 1.091s\n",
      "| Adam | epoch: 024 | loss: 0.54477 - acc: 0.7771 | val_loss: 0.69559 - val_acc: 0.5143 -- iter: 45/45\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32m0.51960\u001b[0m\u001b[0m | time: 1.081s\n",
      "| Adam | epoch: 025 | loss: 0.51960 - acc: 0.8319 | val_loss: 0.71308 - val_acc: 0.7143 -- iter: 45/45\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32m0.50248\u001b[0m\u001b[0m | time: 1.083s\n",
      "| Adam | epoch: 026 | loss: 0.50248 - acc: 0.8705 | val_loss: 0.83237 - val_acc: 0.7143 -- iter: 45/45\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32m0.46579\u001b[0m\u001b[0m | time: 1.082s\n",
      "| Adam | epoch: 027 | loss: 0.46579 - acc: 0.8809 | val_loss: 0.77559 - val_acc: 0.7714 -- iter: 45/45\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32m0.45246\u001b[0m\u001b[0m | time: 1.087s\n",
      "| Adam | epoch: 028 | loss: 0.45246 - acc: 0.8663 | val_loss: 0.77627 - val_acc: 0.6000 -- iter: 45/45\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32m0.41941\u001b[0m\u001b[0m | time: 1.087s\n",
      "| Adam | epoch: 029 | loss: 0.41941 - acc: 0.8988 | val_loss: 0.83542 - val_acc: 0.6000 -- iter: 45/45\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32m0.39844\u001b[0m\u001b[0m | time: 1.087s\n",
      "| Adam | epoch: 030 | loss: 0.39844 - acc: 0.9228 | val_loss: 0.98503 - val_acc: 0.7429 -- iter: 45/45\n",
      "--\n",
      "Training Step: 31  | total loss: \u001b[1m\u001b[32m0.37707\u001b[0m\u001b[0m | time: 1.090s\n",
      "| Adam | epoch: 031 | loss: 0.37707 - acc: 0.9406 | val_loss: 1.37029 - val_acc: 0.6857 -- iter: 45/45\n",
      "--\n",
      "Training Step: 32  | total loss: \u001b[1m\u001b[32m0.35582\u001b[0m\u001b[0m | time: 1.092s\n",
      "| Adam | epoch: 032 | loss: 0.35582 - acc: 0.9540 | val_loss: 1.12447 - val_acc: 0.7143 -- iter: 45/45\n",
      "--\n",
      "Training Step: 33  | total loss: \u001b[1m\u001b[32m0.34658\u001b[0m\u001b[0m | time: 1.082s\n",
      "| Adam | epoch: 033 | loss: 0.34658 - acc: 0.9397 | val_loss: 1.01028 - val_acc: 0.5714 -- iter: 45/45\n",
      "--\n",
      "Training Step: 34  | total loss: \u001b[1m\u001b[32m0.32818\u001b[0m\u001b[0m | time: 1.085s\n",
      "| Adam | epoch: 034 | loss: 0.32818 - acc: 0.9526 | val_loss: 1.02448 - val_acc: 0.5714 -- iter: 45/45\n",
      "--\n",
      "Training Step: 35  | total loss: \u001b[1m\u001b[32m0.31262\u001b[0m\u001b[0m | time: 1.089s\n",
      "| Adam | epoch: 035 | loss: 0.31262 - acc: 0.9625 | val_loss: 1.30829 - val_acc: 0.6286 -- iter: 45/45\n",
      "--\n",
      "Training Step: 36  | total loss: \u001b[1m\u001b[32m0.29764\u001b[0m\u001b[0m | time: 1.078s\n",
      "| Adam | epoch: 036 | loss: 0.29764 - acc: 0.9702 | val_loss: 1.64733 - val_acc: 0.7143 -- iter: 45/45\n",
      "--\n",
      "Training Step: 37  | total loss: \u001b[1m\u001b[32m0.27835\u001b[0m\u001b[0m | time: 1.088s\n",
      "| Adam | epoch: 037 | loss: 0.27835 - acc: 0.9761 | val_loss: 1.25236 - val_acc: 0.5429 -- iter: 45/45\n",
      "--\n",
      "Training Step: 38  | total loss: \u001b[1m\u001b[32m0.96052\u001b[0m\u001b[0m | time: 1.076s\n",
      "| Adam | epoch: 038 | loss: 0.96052 - acc: 0.8765 | val_loss: 1.14142 - val_acc: 0.5143 -- iter: 45/45\n",
      "--\n",
      "Training Step: 39  | total loss: \u001b[1m\u001b[32m0.80302\u001b[0m\u001b[0m | time: 1.090s\n",
      "| Adam | epoch: 039 | loss: 0.80302 - acc: 0.9001 | val_loss: 1.29882 - val_acc: 0.6000 -- iter: 45/45\n",
      "--\n",
      "Training Step: 40  | total loss: \u001b[1m\u001b[32m0.68078\u001b[0m\u001b[0m | time: 1.111s\n",
      "| Adam | epoch: 040 | loss: 0.68078 - acc: 0.9188 | val_loss: 1.47353 - val_acc: 0.6571 -- iter: 45/45\n",
      "--\n",
      "Training Step: 41  | total loss: \u001b[1m\u001b[32m0.56830\u001b[0m\u001b[0m | time: 1.102s\n",
      "| Adam | epoch: 041 | loss: 0.56830 - acc: 0.9338 | val_loss: 1.57502 - val_acc: 0.6286 -- iter: 45/45\n",
      "--\n",
      "Training Step: 42  | total loss: \u001b[1m\u001b[32m0.47281\u001b[0m\u001b[0m | time: 1.085s\n",
      "| Adam | epoch: 042 | loss: 0.47281 - acc: 0.9457 | val_loss: 1.69390 - val_acc: 0.7143 -- iter: 45/45\n",
      "--\n",
      "Training Step: 43  | total loss: \u001b[1m\u001b[32m0.39257\u001b[0m\u001b[0m | time: 1.095s\n",
      "| Adam | epoch: 043 | loss: 0.39257 - acc: 0.9553 | val_loss: 1.83841 - val_acc: 0.6571 -- iter: 45/45\n",
      "--\n",
      "Training Step: 44  | total loss: \u001b[1m\u001b[32m0.32618\u001b[0m\u001b[0m | time: 1.094s\n",
      "| Adam | epoch: 044 | loss: 0.32618 - acc: 0.9630 | val_loss: 2.24729 - val_acc: 0.5714 -- iter: 45/45\n",
      "--\n",
      "Training Step: 45  | total loss: \u001b[1m\u001b[32m0.27104\u001b[0m\u001b[0m | time: 1.092s\n",
      "| Adam | epoch: 045 | loss: 0.27104 - acc: 0.9693 | val_loss: 3.05096 - val_acc: 0.6286 -- iter: 45/45\n",
      "--\n",
      "Training Step: 46  | total loss: \u001b[1m\u001b[32m0.22590\u001b[0m\u001b[0m | time: 1.130s\n",
      "| Adam | epoch: 046 | loss: 0.22590 - acc: 0.9744 | val_loss: 4.16085 - val_acc: 0.5429 -- iter: 45/45\n",
      "--\n",
      "Training Step: 47  | total loss: \u001b[1m\u001b[32m0.18895\u001b[0m\u001b[0m | time: 1.117s\n",
      "| Adam | epoch: 047 | loss: 0.18895 - acc: 0.9786 | val_loss: 5.29967 - val_acc: 0.5143 -- iter: 45/45\n",
      "--\n",
      "Training Step: 48  | total loss: \u001b[1m\u001b[32m0.15868\u001b[0m\u001b[0m | time: 1.172s\n",
      "| Adam | epoch: 048 | loss: 0.15868 - acc: 0.9820 | val_loss: 2.62981 - val_acc: 0.7143 -- iter: 45/45\n",
      "--\n",
      "Training Step: 49  | total loss: \u001b[1m\u001b[32m0.13508\u001b[0m\u001b[0m | time: 1.195s\n",
      "| Adam | epoch: 049 | loss: 0.13508 - acc: 0.9849 | val_loss: 3.63922 - val_acc: 0.7143 -- iter: 45/45\n",
      "--\n",
      "Training Step: 50  | total loss: \u001b[1m\u001b[32m0.11419\u001b[0m\u001b[0m | time: 1.134s\n",
      "| Adam | epoch: 050 | loss: 0.11419 - acc: 0.9872 | val_loss: 3.00814 - val_acc: 0.7429 -- iter: 45/45\n",
      "--\n",
      "Training Step: 51  | total loss: \u001b[1m\u001b[32m0.31499\u001b[0m\u001b[0m | time: 1.108s\n",
      "| Adam | epoch: 051 | loss: 0.31499 - acc: 0.9621 | val_loss: 4.85372 - val_acc: 0.6286 -- iter: 45/45\n",
      "--\n",
      "Training Step: 52  | total loss: \u001b[1m\u001b[32m0.33405\u001b[0m\u001b[0m | time: 1.113s\n",
      "| Adam | epoch: 052 | loss: 0.33405 - acc: 0.9511 | val_loss: 10.81573 - val_acc: 0.3429 -- iter: 45/45\n",
      "--\n",
      "Training Step: 53  | total loss: \u001b[1m\u001b[32m0.28477\u001b[0m\u001b[0m | time: 1.169s\n",
      "| Adam | epoch: 053 | loss: 0.28477 - acc: 0.9583 | val_loss: 10.71390 - val_acc: 0.3429 -- iter: 45/45\n",
      "--\n",
      "Training Step: 54  | total loss: \u001b[1m\u001b[32m1.37507\u001b[0m\u001b[0m | time: 1.134s\n",
      "| Adam | epoch: 054 | loss: 1.37507 - acc: 0.8998 | val_loss: 6.12171 - val_acc: 0.5143 -- iter: 45/45\n",
      "--\n",
      "Training Step: 55  | total loss: \u001b[1m\u001b[32m1.53473\u001b[0m\u001b[0m | time: 1.111s\n",
      "| Adam | epoch: 055 | loss: 1.53473 - acc: 0.8570 | val_loss: 2.60479 - val_acc: 0.6000 -- iter: 45/45\n",
      "--\n",
      "Training Step: 56  | total loss: \u001b[1m\u001b[32m1.31891\u001b[0m\u001b[0m | time: 1.089s\n",
      "| Adam | epoch: 056 | loss: 1.31891 - acc: 0.8771 | val_loss: 2.52347 - val_acc: 0.7429 -- iter: 45/45\n",
      "--\n",
      "Training Step: 57  | total loss: \u001b[1m\u001b[32m1.13629\u001b[0m\u001b[0m | time: 1.115s\n",
      "| Adam | epoch: 057 | loss: 1.13629 - acc: 0.8941 | val_loss: 4.08495 - val_acc: 0.6571 -- iter: 45/45\n",
      "--\n",
      "Training Step: 58  | total loss: \u001b[1m\u001b[32m1.80712\u001b[0m\u001b[0m | time: 1.127s\n",
      "| Adam | epoch: 058 | loss: 1.80712 - acc: 0.8510 | val_loss: 3.62952 - val_acc: 0.6286 -- iter: 45/45\n",
      "--\n",
      "Training Step: 59  | total loss: \u001b[1m\u001b[32m1.95721\u001b[0m\u001b[0m | time: 1.113s\n",
      "| Adam | epoch: 059 | loss: 1.95721 - acc: 0.8113 | val_loss: 2.20346 - val_acc: 0.6571 -- iter: 45/45\n",
      "--\n",
      "Training Step: 60  | total loss: \u001b[1m\u001b[32m2.07472\u001b[0m\u001b[0m | time: 1.109s\n",
      "| Adam | epoch: 060 | loss: 2.07472 - acc: 0.7775 | val_loss: 0.89352 - val_acc: 0.7714 -- iter: 45/45\n",
      "--\n",
      "Training Step: 61  | total loss: \u001b[1m\u001b[32m1.96160\u001b[0m\u001b[0m | time: 1.113s\n",
      "| Adam | epoch: 061 | loss: 1.96160 - acc: 0.7601 | val_loss: 3.18975 - val_acc: 0.5143 -- iter: 45/45\n",
      "--\n",
      "Training Step: 62  | total loss: \u001b[1m\u001b[32m1.71001\u001b[0m\u001b[0m | time: 1.140s\n",
      "| Adam | epoch: 062 | loss: 1.71001 - acc: 0.7909 | val_loss: 4.11903 - val_acc: 0.4000 -- iter: 45/45\n",
      "--\n",
      "Training Step: 63  | total loss: \u001b[1m\u001b[32m1.49964\u001b[0m\u001b[0m | time: 1.080s\n",
      "| Adam | epoch: 063 | loss: 1.49964 - acc: 0.8174 | val_loss: 3.42578 - val_acc: 0.4000 -- iter: 45/45\n",
      "--\n",
      "Training Step: 64  | total loss: \u001b[1m\u001b[32m1.37961\u001b[0m\u001b[0m | time: 1.081s\n",
      "| Adam | epoch: 064 | loss: 1.37961 - acc: 0.8153 | val_loss: 1.83912 - val_acc: 0.5429 -- iter: 45/45\n",
      "--\n",
      "Training Step: 65  | total loss: \u001b[1m\u001b[32m1.23974\u001b[0m\u001b[0m | time: 1.081s\n",
      "| Adam | epoch: 065 | loss: 1.23974 - acc: 0.8298 | val_loss: 0.66635 - val_acc: 0.7429 -- iter: 45/45\n",
      "--\n",
      "Training Step: 66  | total loss: \u001b[1m\u001b[32m1.09868\u001b[0m\u001b[0m | time: 1.114s\n",
      "| Adam | epoch: 066 | loss: 1.09868 - acc: 0.8505 | val_loss: 0.59729 - val_acc: 0.7143 -- iter: 45/45\n",
      "--\n",
      "Training Step: 67  | total loss: \u001b[1m\u001b[32m0.97247\u001b[0m\u001b[0m | time: 1.081s\n",
      "| Adam | epoch: 067 | loss: 0.97247 - acc: 0.8685 | val_loss: 0.58989 - val_acc: 0.7714 -- iter: 45/45\n",
      "--\n",
      "Training Step: 68  | total loss: \u001b[1m\u001b[32m0.87147\u001b[0m\u001b[0m | time: 1.087s\n",
      "| Adam | epoch: 068 | loss: 0.87147 - acc: 0.8735 | val_loss: 0.78406 - val_acc: 0.6857 -- iter: 45/45\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 69  | total loss: \u001b[1m\u001b[32m0.77417\u001b[0m\u001b[0m | time: 1.088s\n",
      "| Adam | epoch: 069 | loss: 0.77417 - acc: 0.8883 | val_loss: 1.40067 - val_acc: 0.5714 -- iter: 45/45\n",
      "--\n",
      "Training Step: 70  | total loss: \u001b[1m\u001b[32m0.68823\u001b[0m\u001b[0m | time: 1.138s\n",
      "| Adam | epoch: 070 | loss: 0.68823 - acc: 0.9012 | val_loss: 1.78966 - val_acc: 0.5714 -- iter: 45/45\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "import tflearn\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.estimator import regression\n",
    "\n",
    "convnet = input_data(shape=[None, IMG_SIZE, IMG_SIZE, 1], name='input')\n",
    "\n",
    "convnet = conv_2d(convnet, 32, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 128, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 32, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 128, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 32, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "\n",
    "convnet = fully_connected(convnet, 1024, activation='relu')\n",
    "convnet = dropout(convnet, 0.8)\n",
    "\n",
    "convnet = fully_connected(convnet, 2, activation='softmax')\n",
    "convnet = regression(convnet, optimizer='adam', learning_rate=LR, loss='categorical_crossentropy', name='targets')\n",
    "\n",
    "model = tflearn.DNN(convnet, tensorboard_dir='log')\n",
    "\n",
    "\n",
    "\n",
    "if os.path.exists('{}.meta'.format(MODEL_NAME)):\n",
    "    model.load(MODEL_NAME)\n",
    "    print('model loaded!')\n",
    "\n",
    "train1 = train_data[:-35]\n",
    "test1 = train_data[-35:]\n",
    "\n",
    "X = np.array([i[0] for i in train1]).reshape(-1,IMG_SIZE,IMG_SIZE,1)\n",
    "Y = [i[1] for i in train1]\n",
    "\n",
    "test_x = np.array([i[0] for i in test1]).reshape(-1,IMG_SIZE,IMG_SIZE,1)\n",
    "test_y = [i[1] for i in test1]\n",
    "\n",
    "model.fit({'input': X}, {'targets': Y}, n_epoch=70, validation_set=({'input': test_x}, {'targets': test_y}), \n",
    "    snapshot_step=500, show_metric=True, run_id=MODEL_NAME)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:00<00:00, 137.87it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# if you need to create the data:\n",
    "test_data = process_test_data()   #returnnig testing_data\n",
    "# if you already have some saved:\n",
    "#test_data = np.load('train_data.npy')\n",
    "\n",
    "fig=plt.figure()\n",
    "\n",
    "for num,data in enumerate(test_data[:10]):\n",
    "    # cat: [1,0]\n",
    "    # dog: [0,1]\n",
    "    \n",
    "    img_num = data[1]\n",
    "    img_data = data[0]\n",
    "    \n",
    "    y = fig.add_subplot(3,4,num+1)\n",
    "    orig = img_data\n",
    "    data = img_data.reshape(IMG_SIZE,IMG_SIZE,1)\n",
    "    #model_out = model.predict([data])[0]\n",
    "    model_out = model.predict([data])[0]\n",
    "    \n",
    "    if np.argmax(model_out) == 1: str_label='sad'\n",
    "    else: str_label='happy'\n",
    "        \n",
    "    y.imshow(orig,cmap='gray')\n",
    "    plt.title(str_label)\n",
    "    y.axes.get_xaxis().set_visible(False)\n",
    "    y.axes.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[195]\n"
     ]
    }
   ],
   "source": [
    "print(data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:00<00:00, 203.77it/s]\n"
     ]
    }
   ],
   "source": [
    "with open('submission_file.csv','w') as f:\n",
    "    f.write('id,label\\n')\n",
    "            \n",
    "with open('submission_file3.csv','a') as f:\n",
    "    for data in tqdm(test_data):\n",
    "        img_num = data[1]\n",
    "        img_data = data[0]\n",
    "        orig = img_data\n",
    "        data = img_data.reshape(IMG_SIZE,IMG_SIZE,1)\n",
    "        model_out = model.predict([data])[0]\n",
    "        f.write('{},{}\\n'.format(img_num,model_out[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't pickle _thread.RLock objects",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-7d3a0355de1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model.pkl'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Loading model to compare the results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model.pkl'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't pickle _thread.RLock objects"
     ]
    }
   ],
   "source": [
    "pickle.dump(model, open('model.pkl','wb'))\n",
    "\n",
    "# Loading model to compare the results\n",
    "model1 = pickle.load(open('model.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
